{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47305788-5dc3-4da2-b074-8de5af108195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q 1 Answer :\n",
    "\"\"\"\n",
    "Lasso Regression is a type of linear regression that uses a regularization technique called L1 regularization. In Lasso Regression,\n",
    "the objective is to minimize the sum of squared residuals between the predicted values and the actual values, subject to a constraint on the sum of\n",
    "the absolute values of the coefficients. This constraint is controlled by a hyperparameter (lambda), which determines the strength of the\n",
    "regularization.\n",
    "\n",
    "Lasso Regression differs from other regression techniques in that it has the ability to perform feature selection, by shrinking the coefficients of\n",
    "less important variables to exactly zero. This is because the L1 regularization penalty promotes sparsity in the coefficients, making it more likely \n",
    "that some coefficients will be exactly zero. In contrast, other regularization techniques like Ridge Regression do not typically result in exact zero\n",
    "coefficients, but rather shrink them towards zero.\n",
    "\n",
    "Lasso Regression can be particularly useful when dealing with high-dimensional datasets with many correlated predictors, as it can help to identify\n",
    "the most important predictors and discard the less relevant ones. However, it can also be more sensitive to outliers and noise in the data,\n",
    "and may not perform as well in situations where all the predictors are potentially important or the correlations are weak.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdd5846-86a0-4bc7-a1de-321546be6e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q 2 Answer :\n",
    "\"\"\"\n",
    "The main advantage of using Lasso Regression in feature selection is that it can automatically perform variable selection and reduce the number of \n",
    "predictors in the model. Lasso Regression adds a penalty term to the sum of squared residuals, which forces some of the coefficients to become zero, \n",
    "effectively removing the corresponding variables from the model. This can help to simplify the model and improve its interpretability, as well as\n",
    "reduce the risk of overfitting. Additionally, Lasso Regression can be useful in situations where the number of variables is large compared to the\n",
    "number of observations, as it can handle high-dimensional data sets.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3899662e-7ca1-4621-a2fb-63a9b123c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q 3 Answer :\n",
    "\"\"\"\n",
    "The interpretation of the coefficients in a Lasso Regression model is similar to that in a standard linear regression model.\n",
    "Each coefficient represents the change in the response variable for a one-unit increase in the corresponding predictor variable,\n",
    "holding all other predictors constant.\n",
    "\n",
    "However, because Lasso Regression can lead to some coefficients being shrunk to zero, it is possible to have some predictors excluded \n",
    "from the final model. This means that the coefficients of the remaining predictors represent their relative importance in predicting the response\n",
    "variable. A coefficient with a large magnitude indicates that the corresponding predictor has a strong influence on the response variable,\n",
    "while a coefficient with a small magnitude indicates a weaker influence.\n",
    "\n",
    "It is also important to note that the sign of the coefficient indicates the direction of the relationship between the predictor and the response\n",
    "variable. A positive coefficient suggests a positive relationship, while a negative coefficient suggests a negative relationship.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd58d4dc-4e9e-4d85-ad02-6db6506074c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q 4 Answer :\n",
    "\"\"\"\n",
    "The main tuning parameter in Lasso Regression is the regularization parameter, also known as lambda (λ). This parameter controls the strength of the \n",
    "penalty term applied to the absolute value of the coefficients.\n",
    "\n",
    "A larger value of lambda results in a more aggressive shrinking of the coefficients towards zero, leading to a more sparse model with fewer predictors.\n",
    "On the other hand, a smaller value of lambda allows for a higher number of non-zero coefficients and may result in overfitting if the number of\n",
    "predictors is large.\n",
    "\n",
    "In addition to lambda, there are other options for tuning the Lasso Regression model, such as choosing the optimization algorithm,\n",
    "setting the convergence criteria, or specifying the type of standardization used for the input features. However, the regularization parameter λ is \n",
    "the most important tuning parameter in Lasso Regression.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ac680-a230-4543-a2dc-5a91af677244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q 5 Answer :\n",
    "\"\"\"\n",
    "Lasso Regression is a linear regression technique that is used to select the most important features from a given set of independent variables.\n",
    "It is primarily used for linear regression problems, where the relationship between the independent and dependent variables is assumed to be linear.\n",
    "\n",
    "However, Lasso Regression can also be used for non-linear regression problems by first transforming the independent variables to a higher order or \n",
    "adding interaction terms. This approach is known as Polynomial Regression or Lasso Polynomial Regression.\n",
    "\n",
    "In Lasso Polynomial Regression, the model is still a linear combination of the features, but the features themselves are a combination of the original\n",
    "features and their higher-order terms or interactions. The Lasso penalty term is then applied to the coefficients of these higher-order terms to \n",
    "select the most important features and to prevent overfitting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6269e8df-4195-41e0-b4db-0c528ece26a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q 6 Answer :\n",
    "\"\"\"\n",
    "Ridge Regression and Lasso Regression are two popular regularization techniques used in linear regression. \n",
    "The main difference between them is the type of penalty applied to the coefficients of the regression model.\n",
    "\n",
    "In Ridge Regression, an L2 penalty is applied to the sum of squared values of the coefficients, while in Lasso Regression,\n",
    "an L1 penalty is applied to the sum of absolute values of the coefficients.\n",
    "\n",
    "The main differences between Ridge and Lasso Regression are:\n",
    "\n",
    "1.Penalty term: Ridge Regression uses an L2 penalty, which adds a squared magnitude of the coefficients to the loss function, while Lasso Regression\n",
    "uses an L1 penalty, which adds the absolute magnitude of the coefficients to the loss function.\n",
    "\n",
    "2.Shrinkage: Ridge Regression shrinks the coefficients towards zero, but does not set them to zero. Lasso Regression, on the other hand,\n",
    "can set some coefficients to exactly zero, resulting in feature selection.\n",
    "\n",
    "3.Number of variables: Ridge Regression is useful when there are many variables in the model, while Lasso Regression can be more effective when there\n",
    "are only a few variables that have a large impact on the response variable.\n",
    "\n",
    "4.Interpretability: Ridge Regression coefficients are shrunk towards zero but remain non-zero, making them difficult to interpret. Lasso Regression, \n",
    "on the other hand, sets some coefficients to exactly zero, resulting in a more interpretable model with a subset of the original variables.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b22852-8b23-45ef-b414-d4aa11de9095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q 7 Answer :\n",
    "\"\"\"\n",
    "Yes, Lasso Regression can handle multicollinearity in the input features. In fact, Lasso Regression has an advantage over Ridge Regression in \n",
    "handling multicollinearity. Lasso Regression performs feature selection by shrinking the coefficients of less important features to zero, effectively \n",
    "removing them from the model. This means that it can choose one feature over another in the presence of multicollinearity, whereas Ridge Regression \n",
    "will simply shrink the coefficients of all correlated features by the same amount.\n",
    "\n",
    "Therefore, Lasso Regression can handle multicollinearity by automatically selecting the most important feature among a group of highly correlated \n",
    "features, effectively reducing their impact on the model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69b2e93-f56c-4c6c-9fc4-52061c282322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q 8 Answer :\n",
    "\"\"\"\n",
    "In Lasso Regression, the optimal value of the regularization parameter (lambda) can be chosen using cross-validation. \n",
    "The data set is divided into several subsets, and the model is trained on a combination of these subsets. \n",
    "The performance of the model is then evaluated on the remaining subset. This process is repeated several times,\n",
    "with different subsets used for training and testing in each iteration. The value of lambda that gives the best performance on the test sets is chosen\n",
    "as the optimal value. This is known as cross-validation or hyperparameter tuning, and it helps to prevent overfitting and improve the model's\n",
    "generalization ability.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
